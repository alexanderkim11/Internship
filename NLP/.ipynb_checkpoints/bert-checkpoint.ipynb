{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0xBADBADBAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords1 = stopwords.words(\"english\")\n",
    "\n",
    "RE_PUNCT = re.compile('([%s])+' % re.escape(string.punctuation), re.UNICODE)\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def preprocess(text):\n",
    "    res = []\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        if token not in stopwords1 and len(token) > 3 and token != \"top.location.href=location.href\":\n",
    "            token = RE_PUNCT.sub(\" \", token)\n",
    "            token = stemmer.stem(token)\n",
    "            res.append(token)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = [x[2] for x in os.walk(str(os.getcwd()) + \"\\\\scripts\")]\n",
    "os.chdir(\"scripts\")\n",
    "try:\n",
    "    corpus = []\n",
    "    files = []\n",
    "    for filename in glob.glob(\"*.txt\"):\n",
    "        file = open(filename, 'r')\n",
    "        tokens = preprocess(file.read())\n",
    "        text = ' '.join(tokens)\n",
    "        corpus.append(text)\n",
    "        files.append(filename)\n",
    "        file.close()\n",
    "    os.chdir(\"..\")\n",
    "except:\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>documents</th>\n",
       "      <th>documents_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-Things-I-Hate-About-You.txt</td>\n",
       "      <td>written karen mccullah lutz  amp  kirsten smit...</td>\n",
       "      <td>written karen mccullah lutz amp kirsten smith ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-and-Holding.txt</td>\n",
       "      <td>written anthoni cipriano twin boys  rudi jacob...</td>\n",
       "      <td>written anthoni cipriano twin boys rudi jacob ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12-Monkeys.txt</td>\n",
       "      <td>origin screenplay david peopl janet peopl insp...</td>\n",
       "      <td>origin screenplay david peopl janet peopl insp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12-Years-a-Slave.txt</td>\n",
       "      <td>written john ridley close pair black hand open...</td>\n",
       "      <td>written john ridley close pair black hand open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127-Hours.txt</td>\n",
       "      <td>written simon beaufoy  amp  danni boyl massiv ...</td>\n",
       "      <td>written simon beaufoy amp danni boyl massiv cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1492-Conquest-of-Paradise.txt</td>\n",
       "      <td>roselyn bosch septemb 1991 start man  eleg sli...</td>\n",
       "      <td>roselyn bosch septemb      start man eleg slip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15-Minutes.txt</td>\n",
       "      <td>word czech airline  pan across word side plane...</td>\n",
       "      <td>word czech airline pan across word side plane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17-Again.txt</td>\n",
       "      <td>written jason filardi octob 2007 car scatter p...</td>\n",
       "      <td>written jason filardi octob      car scatter p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>187.txt</td>\n",
       "      <td>scott yagemann revis shoot draft novemb 1996 e...</td>\n",
       "      <td>scott yagemann revis shoot draft novemb      e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-A-Space-Odyssey.txt</td>\n",
       "      <td>screenplay stanley kubrick arthur clark hawk f...</td>\n",
       "      <td>screenplay stanley kubrick arthur clark hawk f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0  10-Things-I-Hate-About-You.txt   \n",
       "1              12-and-Holding.txt   \n",
       "2                  12-Monkeys.txt   \n",
       "3            12-Years-a-Slave.txt   \n",
       "4                   127-Hours.txt   \n",
       "5   1492-Conquest-of-Paradise.txt   \n",
       "6                  15-Minutes.txt   \n",
       "7                    17-Again.txt   \n",
       "8                         187.txt   \n",
       "9        2001-A-Space-Odyssey.txt   \n",
       "\n",
       "                                           documents  \\\n",
       "0  written karen mccullah lutz  amp  kirsten smit...   \n",
       "1  written anthoni cipriano twin boys  rudi jacob...   \n",
       "2  origin screenplay david peopl janet peopl insp...   \n",
       "3  written john ridley close pair black hand open...   \n",
       "4  written simon beaufoy  amp  danni boyl massiv ...   \n",
       "5  roselyn bosch septemb 1991 start man  eleg sli...   \n",
       "6  word czech airline  pan across word side plane...   \n",
       "7  written jason filardi octob 2007 car scatter p...   \n",
       "8  scott yagemann revis shoot draft novemb 1996 e...   \n",
       "9  screenplay stanley kubrick arthur clark hawk f...   \n",
       "\n",
       "                                   documents_cleaned  \n",
       "0  written karen mccullah lutz amp kirsten smith ...  \n",
       "1  written anthoni cipriano twin boys rudi jacob ...  \n",
       "2  origin screenplay david peopl janet peopl insp...  \n",
       "3  written john ridley close pair black hand open...  \n",
       "4  written simon beaufoy amp danni boyl massiv cr...  \n",
       "5  roselyn bosch septemb      start man eleg slip...  \n",
       "6  word czech airline pan across word side plane ...  \n",
       "7  written jason filardi octob      car scatter p...  \n",
       "8  scott yagemann revis shoot draft novemb      e...  \n",
       "9  screenplay stanley kubrick arthur clark hawk f...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df = pd.DataFrame(files, columns = ['filename'])\n",
    "documents_df[\"documents\"] = corpus\n",
    "documents_df[\"documents_cleaned\"] = documents_df.documents.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ', w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ', w).lower() not in stopwords1))\n",
    "documents_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 690/690 [00:00<00:00, 344kB/s]\n",
      "Downloading: 100%|██████████| 3.67k/3.67k [00:00<00:00, 1.84MB/s]\n",
      "Downloading: 100%|██████████| 629/629 [00:00<00:00, 316kB/s]\n",
      "Downloading: 100%|██████████| 122/122 [00:00<00:00, 81.6kB/s]\n",
      "Downloading: 100%|██████████| 229/229 [00:00<00:00, 115kB/s]\n",
      "Downloading: 100%|██████████| 90.9M/90.9M [00:05<00:00, 17.5MB/s]\n",
      "Downloading: 100%|██████████| 53.0/53.0 [00:00<00:00, 35.5kB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 75.2kB/s]\n",
      "Downloading: 100%|██████████| 466k/466k [00:00<00:00, 2.34MB/s]\n",
      "Downloading: 100%|██████████| 516/516 [00:00<00:00, 346kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 1.75MB/s]\n",
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 95.3kB/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "document_embeddings = sbert_model.encode(documents_df['documents_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(doc_id,similarity_matrix,matrix):\n",
    "    print ('\\n')\n",
    "    print (f'Document: {documents_df.iloc[doc_id][\"filename\"]}')\n",
    "    print ('\\n')\n",
    "    print ('Similar Documents:')\n",
    "    print ('\\n')\n",
    "    if matrix=='Cosine Similarity':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])[::-1]\n",
    "    elif matrix=='Euclidean Distance':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])\n",
    "    for ix in similar_ix[:6]:\n",
    "        if ix==doc_id:\n",
    "            continue\n",
    "        print (f'Document: {documents_df.iloc[ix][\"filename\"]}')\n",
    "        print (f'{matrix} : {similarity_matrix[doc_id][ix]}')\n",
    "        print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(title):\n",
    "    word = title\n",
    "    tokens = word.split()\n",
    "    res = []\n",
    "    for token in tokens:\n",
    "        token = RE_PUNCT.sub(\"\", token)\n",
    "        res.append(token)\n",
    "    boole = False\n",
    "    title = \"\"\n",
    "    for i in range(len(res)):\n",
    "        if (res[i] == \"The\") and i == 0:\n",
    "            boole = True\n",
    "            continue\n",
    "        cur = res[i]\n",
    "        if i == len(res) -  1:\n",
    "            if boole == True:\n",
    "                title += cur + \",-The.txt\"\n",
    "            else:\n",
    "                title += cur + \".txt\"\n",
    "        else:\n",
    "            title += cur + \"-\"\n",
    "    try:\n",
    "        return documents_df[documents_df[\"filename\"] == title].index.values.astype(int)[0]\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_similarities=cosine_similarity(document_embeddings)\n",
    "pairwise_differences=euclidean_distances(document_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Document: Shrek.txt\n",
      "\n",
      "\n",
      "Similar Documents:\n",
      "\n",
      "\n",
      "Document: I,-Robot.txt\n",
      "Cosine Similarity : 0.6147016882896423\n",
      "\n",
      "\n",
      "Document: Shawshank-Redemption,-The.txt\n",
      "Cosine Similarity : 0.610368013381958\n",
      "\n",
      "\n",
      "Document: Black-Swan.txt\n",
      "Cosine Similarity : 0.5945883989334106\n",
      "\n",
      "\n",
      "Document: Juno.txt\n",
      "Cosine Similarity : 0.5930110812187195\n",
      "\n",
      "\n",
      "Document: Austin-Powers---The-Spy-Who-Shagged-Me.txt\n",
      "Cosine Similarity : 0.5918756723403931\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Document: Shrek.txt\n",
      "\n",
      "\n",
      "Similar Documents:\n",
      "\n",
      "\n",
      "Document: Casino.txt\n",
      "Euclidean Distance : 4.136572360992432\n",
      "\n",
      "\n",
      "Document: Bottle-Rocket.txt\n",
      "Euclidean Distance : 4.16238260269165\n",
      "\n",
      "\n",
      "Document: Juno.txt\n",
      "Euclidean Distance : 4.186946868896484\n",
      "\n",
      "\n",
      "Document: Austin-Powers---The-Spy-Who-Shagged-Me.txt\n",
      "Euclidean Distance : 4.2118754386901855\n",
      "\n",
      "\n",
      "Document: Fair-Game.txt\n",
      "Euclidean Distance : 4.297587871551514\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "term = input(\"Provide a Movie Title: \")\n",
    "index = search(term)\n",
    "try:\n",
    "    most_similar(index,pairwise_similarities,'Cosine Similarity')\n",
    "    print(\"-------------------------------------------------------------------------------------------\")\n",
    "    most_similar(index,pairwise_differences,'Euclidean Distance')\n",
    "except:\n",
    "    print(\"Movie not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1941883b2709250a3f9aea35aca4c9fe4a91c6d7b9f42dc68c18bae16893a92"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
